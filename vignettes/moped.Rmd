---
title: "moped: Multivariate Orthogonal Polynomial-based Estimation of Density"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{moped}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
#library(moped)
```

The `moped` package applies the multivariate moment-based density estimation method outlined in Wakefield et. al. (2022) . The purpose of this package is to implement orthogonal polynomial-based joint density estimation to multivariate continuous sample data, obtain density and probability estimates from both the "complete" joint distribution and all marginal distribution estimates, and simulate "synthetic" sample data from said density estimates. The package has considerable use cases in density-based imputation for missing data, robust non-parametric density estimation on aggregated data, and to produce anonymised "synthetic" representative data for the purposes of public dissemination in place of confidential micro-data. Orthogonal polynomial-based density estimation has also been shown to have applications previously in areas such as engineering, physics, and finance \citep{Munkhammar2017}.

In the following report, we lay out some of the important features of the `moped` package and provide examples of code usage that may assist in the further application of these density estimates.

## Estimating Joint Densities with `moped` on Continuous Sample Data

The theoretical results underpinning the sample moment-based density estimate implemented in `moped` can be found in Wakefield et. al. (2022). We note that to avoid word encumbered, we will refer to the "multivariate sample moment-based density estimate" described in Wakefield et. al. (2022) as simply the "moped estimate". We provide a brief summary of the results outlined in Wakefield et. al. (2022) in the following section.

### The mathematical underpinnings of the moped estimate

The moped estimate is constructed of a few fundamental components: (i) the reference distribution, (ii) the multivariate hyper-geometric type polynomials, (iii) the multivariate moment-based density expression, and (iv) the moped estimate. We will look at each of these components in the following sections

#### The reference distribution

To obtain a moped estimate of the continuous random vector $\mathbf{X}=(X_1,X_2,\dots,X_N)$ of dimension $N$, a "reference" distribution for each $k$th random variable $X_k$ is needed to be specified. The reference distribution of random vector $\nu = (\nu_1,\nu_2,\dots,\nu_N)$ serves as the initial basis of the moped estimate and has reference density $f_{\nu} = \prod_{k=1}^N f_{\nu_k}$ where $f_{\nu_k}$ is the density of each $\nu_k$. We require that for each $k$th variable, the sample space of $X_k$ denoted $\Omega_k=[a_k,b_k]$ is also the sample space of $\nu_k$ (i.e. $\nu_k \in \Omega_k$), and $\{\nu_k\}_{k=1,2,\dots,N}$ are mutually independent. We also require that the joint density function $f_{\mathbf{X}} :\mathbb{R}^N \rightarrow\mathbb{R}$ of the random vector $\mathbf{X}$ is defined on the product space $\Omega^{(N)}=\prod_{k=1}^N\Omega_k = \prod_{k=1}^N[a_k,b_k]$. We note that the random vector $\nu$ has sample space $\Omega^{(N)}$.

We require that for each $f_{\nu_k}$ there exists polynomial functions $\sigma_k(x) = \phi_{k,2}x^2 + \phi_{k,1}x + \phi_{k,0} \tag{1}$ and $\tau_k(x) = \psi_{k,1}x + \psi_{k,0}\tag{2}$ of degree 2 and 1 respectively such that,

$$
\frac{d}{dx}\left[ \sigma_{k}(x)f_{\nu_k}(x)\right] = \tau_k(x)f_{\nu_k}(x) \tag{3}
$$

with boundary conditions, for $i=0,1,\dots$

$$
\lim_{x\rightarrow a_k} x^i\sigma_k(x)f_{\nu_k}(x) = \lim_{x\rightarrow b_k} x^i\sigma_k(x)f_{\nu_k}(x)= 0.
$$

Note these properties were outlined in \cite{Sanchez1997}.

Common examples of reference distributions that can be used in the moped estimate are given in the table below. Note, all of the reference distributions listed below can be applied in the `moped` package.

+------------------------+-----------------------------------------------------------------+------------------+-------------------------------+-----------+----------+
| **Distribution**       | $f_{\nu_k}$                                                     | $\sigma_{\nu_k}$ | $\tau_{\nu_k}$                | $a_k$     | $b_k$    |
+========================+=================================================================+==================+===============================+===========+==========+
| Normal $(m, s)$        | $\frac{1}{\sqrt{2 \pi s^2 }}e^{- \frac{(x-m)^2}{2 s^2}}$        | $-s^2$           | $x-m$                         | $-\infty$ | $\infty$ |
+------------------------+-----------------------------------------------------------------+------------------+-------------------------------+-----------+----------+
| Gamma $(\alpha,\beta)$ | $\frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}$ | $x$              | $\alpha - \beta x$            | $0$       | $\infty$ |
+------------------------+-----------------------------------------------------------------+------------------+-------------------------------+-----------+----------+
| Uniform $(u,v)$        | $\frac{1}{v-u}$                                                 | $(x-u)(x-v)$     | $2x -(u+v)$                   | $u$       | $v$      |
+------------------------+-----------------------------------------------------------------+------------------+-------------------------------+-----------+----------+
| Beta $(\alpha,\beta)$  | $\frac{x^{\alpha - 1}(1-x)^{\beta - 1}}{B(\alpha,\beta)}$       | $x(1-x)$         | $-(\alpha + \beta)x + \alpha$ | 0         | 1        |
+------------------------+-----------------------------------------------------------------+------------------+-------------------------------+-----------+----------+

: Table 1: Potential reference densities that satisfy the Sturm Louisville differential equation and can be implemented in `moped` for joint density estimation.

#### The multivariate hyper-geometric type polynomials

The marginal hyper-geometric type polynomials for each reference distribution $\nu_k$ follow from the Sturm-Louisville differential equation expressed in (3).

Essentially, given there exists a reference density $f_{\nu_k}$ that meets the requirements of our reference density, then there exists polynomials, $\{P_{k,n_k}(x_k)\}_{n_k = 0,1,2,\dots}$ which are eigenfunction solutions to the differential equation

$$
\sigma_{k}(x_k)P_{k,n_k}''(x_k)+\tau_{k,n_k}(x_k)P_{k,n_k}'(x_k) - \lambda_{k,n_k}P_{k,n_k}(x_k) = 0
$$

with eigenvalues $\lambda_{k,n_k}= n\psi_{k,1}+\frac{1}{2}n(n-1)\phi_{k,2} \tag{4}.$

The marginal hyper-geometric type polynomials $\{P_{k,n_k}(x_k)\}_{n_k = 0,1,2,\dots}$ are polynomials of degree $n_k$ of the form,

$$
P_{k,n_k}(x_k) = \frac{B_{k,n_k}}{f_{\nu_k}(x_k)}\frac{d^{n_k}}{dx_k^{n_k}}\left[(\sigma_k(x_k))^{n_k}f_{\nu_k}(x_k)\right]
$$

which when we take the value of $B_{k,n_k}$ as follows,

$$
 B_{k,0} = 1, \qquad B_{k,n_k} = \sqrt{ \frac{(-1)^{n_k} \prod_{i_k=0}^{n_k-1} \left[\frac{1}{ \psi_{k,1} + \frac{1}{2}(n_k + i_k -1)\phi_{k,2}}\right] }{ n_k! \int_{a_k}^{b_k} (\sigma_k(t))^{n_k}f_{\nu_k}(t) dt}, } \quad \text{ for } n_k = 1,2,\dots, \tag{5}
$$

are orthonormal with respect to the reference density $f_{\nu_k}$, i.e.

$$ 
\int_{\Omega_k}P_{k,n_k}(x_k)P_{k,m_k}(x_k)f_{\nu_k}(x_k)dx_k = \delta_{n_k=m_k}
$$

where $\delta_{n_k=m_k}$ is the Kronecker delta and is 1 when $n_k=m_k$ and 0 otherwise.

We note that each polynomial can be expressed as $P_{k,n_k}(x_k) = \sum_{i_k=0}^{n_k}a_{k,n_k,i_k}x^{i_k}$, where the coefficients $a_{n_k,i_k}$ are given by,

$$
a_{k,n_k,i_k} =
\begin{cases}
 \frac{a_{k,n_k,i_k+1}(i_k + 1)(i_k \phi_{k,1} + \psi_{k,0}) + a_{k,n_k,i_k+2}(i_k +2)(i_k + 1)\phi_{k,0}}{\lambda_{k,n_k} - \frac{1}{2}i_k(i_k - 1)\phi_{k,2} - i_k\psi_{k,1}}, & i_k = 0,\dots,n_k-2 \\
 \kappa_{k,n_k} \frac{n_k (n_k -1)\phi_{k,1} + n_k \psi_{k,0}}{ \psi_{k,1} + (n_k - 1)\phi_{k,2}}, & i_k = n_k-1\\
  \kappa_{k,n_k},  & i_k = n_k
\end{cases},\tag{6}
$$

where $\kappa_{k,n_k} = B_{k,n_k} \prod_{i_k=0}^{n_k-1} \left[ \psi_{k,1} + \frac{1}{2}(n_k + i_k -1)\phi_{k,2} \right] \text{ and } \kappa_{k,0} =1. \tag{7}$

We define the **multivariate** **hyper-geometric type polynomials** as being the product of the marginal hyper-geometric type polynomials across the $N$ dimensions, i.e.,

$$
P_{n_1,\dots,n_N}(\mathbf{x}) = \prod_{k=1}^NP_{k,n_k}(x_k), \quad \text{where } \mathbf{x}=(x_1,x_2,\dots,x_N).\tag{8}
$$

As shown in Wakefield et. al. (2022), the multivariate hyper-geometric type polynomials are orthonormal in $\Omega^{(N)}$ with respect to the reference density $f_{\nu}$, i.e.,

$$
\int_{\Omega^{(N)}} P_{n_1,\dots,n_N}(\mathbf{x})P_{m_1,\dots,m_N}(\mathbf{x})f_{\nu}(\mathbf{x})d\mathbf{x} = \prod_{k=1}^N\delta_{n_k=m_k},
$$

where $\delta_{n_k=m_k}$ is the Kronecker delta that is 1 when $n_k=m_k$ and 0 otherwise.

The multivariate polynomials also serve as complete basis functions for approximation of multivariate continuous functions defined on $\Omega^{(N)}$.

#### Multivariate moment-based density expression

Following from the derivation of multivariate hyper-geometric type polynomials, in Wakefield et. al. (2022) we showed that provided $\int_{\Omega^{(N)}}\frac{f_{\mathbf{X}}(\mathbf{x})^2}{f_{\nu}(\mathbf{x})}d\mathbf{x}<\infty$ and $f_{\mathbf{X}}(\mathbf{x})$ has finite moments, then $f_{\mathbf{X}}(\mathbf{x})$ has a moment-based density expression given by,

$$
f_{\mathbf{X}}(\mathbf{x}) = f_{\nu}(\mathbf{x})\sum_{n_1 = 0}^{\infty} \dots \sum_{n_N = 0}^{\infty} C_{n_1,\dots,n_N} P_{n_1,\dots,n_N}(\mathbf{x}),\tag{9}
$$

where $C_{n_1,\dots,n_N} = \mathbb{E}_{\mathbf{X}}\left[P_{n_1,\dots,n_N}(\mathbf{X}) \right] = \sum_{i_1=0}^{n_1}\dots\sum_{i_N=0}^{n_N}\left[\prod_{k=1}^N a_{k,n_k,i_k}\right]\mathbb{E}_\mathbf{X}\left[X_1^{i_1}\dots X_N^{i_N}\right]$.

This expression forms the central justification for the `moped` estimate, which instead is based on sample moment data and has finite polynomial order in the summation.

#### The moped estimate

Given a random sample $\{\mathbf{x}_j\}_{j=1}^M =\{(x_{1,j},x_{2,j}, \dots, x_{N,j})\}_{j=1}^M$ of $\mathbf{X} = (X_1,X_2,\dots,X_N)$, with joint density $f_{\mathbf{X}}$ that has a multivariate moment-based density expression, we obtain an estimate of $f_{\mathbf{X}}$ denoted

$\hat{f}_{\mathbf{X};\mathbf{K}}$ with maximum polynomial order $\mathbf{K}=(K_1,\dots,K_N)$, given by,

$$
\hat{f}_{\mathbf{X};\mathbf{K}}(\mathbf{x}; \{\mathbf{x}_j\}_{j=1}^M ) = f_{\nu}(\mathbf{x})\sum_{n_1 = 0}^{K_1} \dots \sum_{n_N = 0}^{K_N} \hat{C}_{n_1,\dots,n_N} P_{n_1,\dots,n_N}(\mathbf{x}),\tag{10}
$$

where $\hat{C}_{n_1,\dots,n_N} = (1 / M) \sum_{j=0}^M P_{n_1,\dots,n_N}(x_{1,j},\dots,x_{N,j}). \tag{11}$

### Fitting the moped estimate using `moped()`

```{r}

```

The moped estimate requires specification of the maximum polynomial order parameter $\mathbf{K}$, in addition to the choice of reference density. In the following section, we outline a computational strategy to estimate the "optimal" maximum polynomial order based on sample data.

### Estimation of the Optimal Maximum Polynomial Order with `validate.mpo()`

Within Wakefield et. al. (2022) we show there exists a finite optimal maximum polynomial order $\mathbf{K}^{*}$ that minimises the $1/f_{\nu}$-weighted $L_2$ norm which we denote $\mathcal{N}_\mathbf{K}$, provided the estimated coefficients $\hat{C}_{n_1,\dots,n_N}$ have non-zero variance as their order increases. That is, provided there exists $m_1,\dots,m_n$ such that for all $n_1>m_1,\dots,n_N>m_N$, $\text{Var}\left(\hat{C}_{n_1,\dots,n_N}\right)>0$ then there exists finite $\mathbf{K}^{*} =(K_1^{*},\dots,K_N^{*})$ i.e. $K_1^{*}<\infty,\dots,K_N^{*}<\infty$, such that, $$
\mathcal{N}_{\mathbf{K}^{*}}\left(\{\mathbf{x}_j\}_{j=1}^M\right) = \int_{\Omega^{(N)}}\frac{\left|\hat{f}_{\mathbf{X};\mathbf{K}^{*}}(\mathbf{x}; \{\mathbf{x}_j\}_{j=1}^M ) -f_{\mathbf{X}}(\mathbf{x})\right|^2}{f_{\nu}(\mathbf{x})}d\mathbf{x}
\qquad \text{is at a minimum.} \tag{12}$$

Unfortunately, the exact value of this statistic can not be determined based on sample data alone. In order to minimise this statistic, an estimation process must be implemented. But with rearrangement and simplification of the expression of $\mathcal{N}_\mathbf{K}$ given in (12), we can see how an estimation procedure may be developed. Rearranging the expression of $\mathcal{N}_\mathbf{K}$ and simplifying we have,

$$
\mathcal{N}_{\mathbf{K}^{*}}\left(\{\mathbf{x}_j\}_{j=1}^M\right) + \int_{\Omega^{(N)}}\frac{f_{\mathbf{X}}(\mathbf{x})^2}{f_{\nu}(\mathbf{x})}d\mathbf{x} = \sum_{n_1=0}^{K_1}\dots\sum_{n_N=0}^{K_N}\hat{C}_{n_1,\dots,n_N}^2 + \sum_{n_1=0}^{K_1}\dots\sum_{n_N=0}^{K_N}\hat{C}_{n_1,\dots,n_N}C_{n_1,\dots,n_N},\tag{13}
$$where $\hat{C}_{n_1,\dots,n_N} = (1 / M) \sum_{j=0}^M P_{n_1,\dots,n_N}(\mathbf{x_{j}})$, $C_{n_1,\dots,n_N} = \mathbb{E}_\mathbf{X}\left[P_{n_1,\dots,n_N}(\mathbf{X})\right]$, and

$\int_{\Omega^{(N)}}\frac{f_{\mathbf{X}}(\mathbf{x})^2}{f_{\nu}(\mathbf{x})}d\mathbf{x}<\infty$ is constant with respect to $\mathbf{K}$.

Therefore, we can obtain the optimal maximum polynomial order $\mathbf{K}^{*}$, by minimising only the right hand side of equation (13) as the left hand side can be considered as the $\mathcal N_\mathbf{K}$ norm shifted by a constant (with respect to $\mathbf{K}$.

Given another random sample $\{\mathbf{y}_j\}_{j=1}^{M_y}$, we can obtain another independent estimate for $C_{n_1,\dots,n_N}$ given by $\hat{C}_{n_1,\dots,n_N}^{(y)} = (1 / M_y) \sum_{j=0}^{M_y} P_{n_1,\dots,n_N}(\mathbf{y_{j}})$. In practice however, we are usually only issued one random sample. In Wakefield et. al. (2022) we proposed a strategy of repeated splitting of the sample, which is analogous to 2-fold repeated cross validation. In the `moped` package, we implement $n$-fold repeated cross validation to determine $\mathbf{K}^{*}$ and also to determine the variable constant $K^{*}$ which is the optimal maximum polynomial order under the condition that $K_{k_1}^{*}=K_{k_2}^{*}$ for all $k_1,k_2 = 1,\dots,N$.

## Predicting Density and Probability Values with `predict.moped()`

### Predicting Density Values (`type="density"`)

### Predicting Distribution Function Probabilities (`type="distribution"`)

### Predicting Conditional Distribution Function Probabilities (`type="conditional"`) 

### Estimation of Conditional DF and Marginal CDF with `estimate.conditional()` and `estimate.marg.cdf()`.

## Sampling from the `moped` Estimate with `m.resample()` 

### Sampling from a moped estimate with `Uniform` reference density

### Sampling from a moped estimate with non-`Uniform` reference density

## Handling Categorical Variables with `make.cont()` and `make.cat()` 

## A Complete Worked Example

## Notation Glossary

The following notation will be used as standard throughout the following sections of the vignette.

+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Notation                                                                 | Index                                            | Description                                                                                                                                                                                                                                                                           |
+==========================================================================+==================================================+=======================================================================================================================================================================================================================================================================================+
| $N$                                                                      |                                                  | Number of variables being estimated.                                                                                                                                                                                                                                                  |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $\mathbf{X} = (X_1,X_2,\dots,X_N)$                                       |                                                  | Random vector of $N$ random variables to be estimated.                                                                                                                                                                                                                                |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $\Omega^{(N)}$                                                           |                                                  | N-dimensional sample space of $\mathbf{X}$.                                                                                                                                                                                                                                           |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $f_{\mathbf{X}}(\mathbf{x})$                                             | $\mathbf{X} = (X_1,X_2,\dots,X_N)$               | The true $N$-dimensional joint density function of $\mathbf{X}$.                                                                                                                                                                                                                      |
|                                                                          |                                                  |                                                                                                                                                                                                                                                                                       |
|                                                                          | $\mathbf{x} = (x_1,x_2,\dots,x_N)$               |                                                                                                                                                                                                                                                                                       |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $\Omega_k =[a_k,b_k]$                                                    | $k=1,\dots,N$                                    | Lower bounds ($a_k$) and upper bounds ($b_k$) of each $k$th element of $\mathbf{X}$.                                                                                                                                                                                                  |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $f_\nu(\mathbf{x})$                                                      | $\nu = (\nu_1,\nu_2,\dots,\nu_N)$,               | $N$-dimensional "reference" density corresponding to the orthogonality weight function of the multivariate orthogonal polynomials.                                                                                                                                                    |
|                                                                          |                                                  |                                                                                                                                                                                                                                                                                       |
|                                                                          | $\mathbf{x} = (x_1,x_2,\dots,x_N)$               |                                                                                                                                                                                                                                                                                       |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $f_{\nu_k}(x_k)$                                                         | $k=1,\dots,N$                                    | The $k$th "reference" density related to the orthogonality weight function of the $k$th marginal orthogonal polynomial.                                                                                                                                                               |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $\sigma_k(x_k)$                                                          | $k=1,\dots,N$                                    | Quadratic polynomial corresponding to each $k$th reference density. Appears in the Sturm-Louisville differential equation of the polynomials.                                                                                                                                         |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $\tau_k(x_k)$                                                            | $k=1,\dots,N$                                    | Linear polynomial corresponding to each $k$th reference density. Appears in the Sturm-Louisville differential equation of the polynomials.                                                                                                                                            |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $\lambda_{k,n_k}$                                                        | $k=1,\dots,N$,                                   | Eigenvalues corresponding to the $n_k$th eigenfunction solution of the Sturm-Louisville differential equation of the polynomials for each $k$th reference density.                                                                                                                    |
|                                                                          |                                                  |                                                                                                                                                                                                                                                                                       |
|                                                                          | $n_k=0,1,2, \dots$                               |                                                                                                                                                                                                                                                                                       |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $P_{n_1,\dots,n_N}(\mathbf{x})$                                          | $\mathbf{x} = (x_1,x_2,\dots,x_N)$               | The $n_1,n_2,\dots,n_N$ order multivariate hyper-geometric type orthogonal polynomial corresponding to the reference density $f_{\nu}(\mathbf{x})$.                                                                                                                                   |
|                                                                          |                                                  |                                                                                                                                                                                                                                                                                       |
|                                                                          | $n_1 = 0, 1, 2, \dots$                           |                                                                                                                                                                                                                                                                                       |
|                                                                          |                                                  |                                                                                                                                                                                                                                                                                       |
|                                                                          | $n_2 = 0,1,2,\dots$                              |                                                                                                                                                                                                                                                                                       |
|                                                                          |                                                  |                                                                                                                                                                                                                                                                                       |
|                                                                          | $\vdots$                                         |                                                                                                                                                                                                                                                                                       |
|                                                                          |                                                  |                                                                                                                                                                                                                                                                                       |
|                                                                          | $n_N = 0,1,2,\dots$                              |                                                                                                                                                                                                                                                                                       |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $P_{k,n_k}(x_k) = \sum_{i_k=0}^{n_k}a_{k,n_k,i_k}x_k^{i_k}$              | $k=1,2,\dots,N$                                  | The $n_k$th order $k$th marginal hyper-geometric type orthogonal polynomial corresponding to the marginal reference density $f_{\nu_k}(x_k)$. The constants $a_{k,n_k,i_k}$ denote the coefficient $i_k$th term in the $n_k$th order polynomial corresponding to the $k$th variable . |
|                                                                          |                                                  |                                                                                                                                                                                                                                                                                       |
|                                                                          | $n_k = 0,1,2,\dots$                              |                                                                                                                                                                                                                                                                                       |
|                                                                          |                                                  |                                                                                                                                                                                                                                                                                       |
|                                                                          | $i_k = 0,1,2,\dots,n_k$                          |                                                                                                                                                                                                                                                                                       |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $M$                                                                      |                                                  | Size of a random sample.                                                                                                                                                                                                                                                              |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $\{\mathbf{x}_j\}_{j=1}^M$                                               | $j=1,2,\dots,M$                                  | Random sample of size $M$ with each $j$th observation a random vector $\mathbf{x}_j$ with joint density function $f_{\mathbf{X}}(\mathbf{x})$.                                                                                                                                        |
|                                                                          |                                                  |                                                                                                                                                                                                                                                                                       |
|                                                                          | $\mathbf{x}_j = (x_{1,j},x_{2,j},\dots,x_{N,j})$ |                                                                                                                                                                                                                                                                                       |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| $\hat{f}_{\mathbf{X};\mathbf{K}}(\mathbf{x}; \{\mathbf{x}_j\}_{j=1}^M )$ | $\mathbf{K} = (K_1,K_2,\dots,K_N)$               | The moped estimate of max polynomial order $\mathbf{K}$.                                                                                                                                                                                                                              |
+--------------------------------------------------------------------------+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

```{r}

```
